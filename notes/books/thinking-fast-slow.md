# Thinking Fast And Slow

Notes from the book [Thinking Fast and Slow](https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow).

## Friendship and Collaboration

On the beginning of the book it caught my attention the author history
with one of his friends and main collaborators on all his research along
his life. They worked together for decades and they rarely agreed 100%
on anything, and yet the disagreements were productive. I find this kind
of balance intriguing, it is rare to find. So when he tried to describe why
it worked ou so well I paid some extra attention:

```
We were sufficiently similar to understand each other easily, and sufficiently
different to surprise each other.
```

It is really hard to hit that nice spot, when you do consider yourself lucky :-).

Off topic but I also found interesting how long walks to think things through
are essential to the author. I find it interesting mostly because I also depend
a lot on that and it always feels good to find kindred spirits.

There is also a degree of luck on how their research was done, the methodology
they choose was very efficient and produced great results, but the main reason
they choose it was because it was the most fun one, they were not trying
to come up with something great, they just did what was more fun.

It is a recurrent topic along the book how luck plays a huge role on most
achievements, both in research and industry. Of course you can't be lucky if
you are not doing anything, but just doing and even skill is not enough, you
need some luck too (that is why it is essential to keep trying, statistically
you are bound to some luck).

## The Two Systems

One of the first models presented on the book and the one more largely utilized
is the two systems model. Basically it splits our cognition/brain into two systems,
they are named 1 and 2, for simplicity (sometimes people refer to it as left/right
brain, or irrational/rational, but reality is more complex than that, so the
author just goes with 1/2).

System 1 is:

* Fast
* Parallel
* Intuitive (pattern recognitiion)
* Associative
* Creative (built on associativity)
* Seeks Causality / Coherence
* Story telling oriented

System 2 is:

* Slow
* Linear
* Logical
* Analytical

A lot of what we are on the conscient level is System 2, it is were language is.
But a lot of what makes us awesome, the magical associative machine, is System 1.
Most of the book explores biases and issues that arise from how we end up relying
way too much on System 1. It is quite fast and cheap, and it is right a lot of times,
but it can be remarkably wrong and it has no way to detect it is wrong.

One example is that System 1 craves causality and story telling. If a story makes sense
and it fits with your belief system, system 1 will buy it, even if the story
is completely disconected from reality and makes no sense at all outside
your belief system. If it matches what you believe it is confortable, and System 1
optimizes for confort.

Cognitive dissonance, the struggle of reassessing your world view, that is System 2.
It is expensive and it is unconfortable, hence most people don't do it very much.

This is pretty much the core from were a bunch of very interesting biases and issues
arise in our cognitive processes. In the end we are neither rational or irrational,
we are something else, an amalgamation of both interacting in useful ways.

It is important to remember were we came from. In nature resources are scarce.
That is why we are intrinsically lazy and use as little as possible from System 2.
For the first time in human history we actually have resources an time to focus
on System 2 activities. The life of our ancestors were quite different, and this
dictates how our brains are wired. And the best you can do is have more awareness
of this, but the biases/pitfalls are literally unavoidable, unless you are not human.

## Thinking is a phisical activity

When you engange into thinking, System 2 thinking, your whole body engages into it.
Research shows that your pupils dilate and your heart rate changes when you
start to engage into tasks that require a lot of system 2 thinking. It is a demanding
activity for your whole body, that is why we are pretty lazy about it.

## Ego Depletion

When you need to excert discipline and self control, an activity that is system 2,
you use a lot of energy. It is not as obvious as when you run and feel tired, but
it is there. Research showed how people after having to excert a lot of self control
gave up easier in a next challenge than people who were just starting.

This phenomenon is referred as **ego depletion**. When your ego is depleted you will
be much more prone to make decisions with your System 1, because you are literally
exausted mentally.

This also applies to when you have to do something that you don't want to do.
I immediately made a connection between this and meetings. I always found amazing
how meetings have the ability of completely fuck up my entire day, even when it is
"just" an hour or two. The fact that I need to force myself to do something
I don't want to and don't see the point causes burns through the ego, and then
you have the cost of the interruption itself. In the end it makes perfect sense
that one or two meetings can destroy a day. It seems exagerated, I always felt
more sensible than the normal, specially because Im usually the only one complaining.
But apparently there is some research backing this up and
[Im not the only one to feel his way](http://paulgraham.com/makersschedule.html).

## Mood and System 1

Some research is mentioned linking the effects of bad mood and System 1.
When you are in a bad mood your system 1 is impaired. That is why it is hard to
be creative when you are in a bad mood, have ideas, make associations, etc.

System 2 is much less affected, so you can still perform more analytical activities.

## Biases

Now a list of the biases mentioned throughout the book.

### Consistency and simplicity over accuracy

Our system 1 is predominantly driven by consistency and simplicity in the story
it tells about ourselves and the world. It doesn't enjoy [cognitive dissonance](https://en.wikipedia.org/wiki/Cognitive_dissonance),
even though exposing yourself to it constantly is essential to build critical
thinking.

What does this mean ? It means that when exposed to new information your mind will
prioritize information that already fits on your current mental model of things,
because that is comfortable and makes it easy to create a simple and consistent
narrative about things. If the information is real/accurate is completely irrelevant
to this process

What does this mean ? It means that when exposed to new information your mind will
prioritize information that already fits on your current mental model of things,
because that is comfortable and makes it easy to create a simple and consistent
narrative about things. If the information is real/accurate is completely irrelevant
to this process.

That is why it is so common for people being exposed to a single side of an argument
to be more sure about their conclusions than people exposed to both. If the
mental model is cohesive it feels strong, even if it is all based on lies
or senseless logic.

Since we are talking about systems this reminded me of the great article
[Worse Is Better](https://www.jwz.org/doc/worse-is-better.html). When explaining the
differences between different design philosophies the author presents 4 main
concepts important when designing systems (or building mental models in this case):

* Simplicity
* Correctness
* Consistency
* Completeness

Both in life and software, you can't have it all, you constantly need to make
tradeoffs on which one will you optimize. Specially when you think about reality,
modeling the world, interactions between people, countries, climate, etc, it is my
opinion that simplicity just flew through the window, reality is not simple.

But then the bad news. Given our limitations as humans we are actually pretty fond
of simplicity. According to research mentioned in the book, specially our
system 1/intuition, is extremelly prone to focusing entirely on simplicity and
consistency. It doesn't matter if the information is correct and it doesn't
matter if you have all information.

One of the biases mentioned on the book is WYSIATI, which stands for What You
See Is All There Is. It reinforces how we always optimize for recent/available
information, hence why we hardly really try to obtain a complete view of
something before coming to a conclusion about it.

My empirical life experience agrees a lot with all this, by observing other
people behavior, and sometimes my own. But maybe I'm just a victim of my
own WYSIATI :-).

### Affect Heuristics

Even our logical/rational System 2 tends to look for information that confirms
System 1 assumptions. I feel this clearly in my life, it is that nice pleasure
you feel when you find information that reinforces something you believe and
that is important for you. But that is also how information bubbles gets formed.

### Anchoring Effect

Suggesting an initial value/information affects your judgement. Even professionals
with a lot of experience get influenced by almost random anchors. Research interviewed
real state agents about the pricing of some real state but providing anchors on
the value of the properties. The anchoring effect was very similar to what
is observed in people who are not giving a professional opinion. So even having
a lot of experience with something won't make you immune to this.
Funny enough the interviewed people denied being influenced by this bias, even
though the results were quite clear.

### Availability Bias

How easily/fast information can be retrieved from our brains affects our confidence
on the information and reinforces our belief in it. This seems ok/good at first,
but leads to some paradoxical results.

In one of the researches around this people were asked to remember of 12 times
they were assertive, and they asked how assertive they think they are. The same
was done with a different set of people, but asking for just 6 times.

Logically, people who remembered fewer ocassions would feel less confident.
But the opposite happened, people who remembered only 6 occasions were more confident
than the ones who remember 12.

Remembering 12 occasions takes longer and is harder. When it is hard to remember
something you develop the intuition that it is less likely to be true, even
if in the end you gathered even more information.

This explains my personal bias against assertive people. Usually the people with
less information/experience are the more assertive ones.

### Affect Heuristic

We tend to not assess tradeoffs between different ideas/things, we just push for simpler
and black/white models of reality. What we like tend to have only benefits and
mostly no downsides, and what we don't like has only downsides, no benefits at all.

This explains a lot about human nature and why almost any form of human endeavour
ends up converging to religious behavior. Religion is usually built on top of
this bias, the affinity that we have with simple answers, right and wrong,
good and evil.

It doesn't model reality, but our brains are not that interested in reality :-)
(just the bare minimum to keep us alive and confortable).
